{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import re\n",
    "import csv\n",
    "import duckdb\n",
    "\n",
    "# internal representation\n",
    "from protein_db import ProteinDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=ProteinDB.db_string)\n",
    "\n",
    "res = con.execute(\"DROP TABLE PFAM_TOKEN\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "con = duckdb.connect(database=ProteinDB.db_string)\n",
    "\n",
    "con.execute(\"\\\n",
    "    CREATE TABLE PFAM_TOKEN(\\\n",
    "        UNIPROT_ID VARCHAR,\\\n",
    "        TOKEN VARCHAR,\\\n",
    "        START_POS USMALLINT,\\\n",
    "        END_POS USMALLINT\\\n",
    "    )\")\n",
    "\n",
    "con.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is instantaneous but not sure where it goes or how to query\n",
    "file = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/pfam_entries_full.dat\"\n",
    "duckdb.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS WORKS 0 CREATES A TABLE WITH COLUMNS : column0, column1 etc\n",
    "# \n",
    "# this took 2mins 17s to load 300M entries - 298,766,058\n",
    "#\n",
    "#\n",
    "con = duckdb.connect(database=ProteinDB.db_string)           \n",
    "\n",
    "con.execute(\"CREATE TABLE PFAM_TOKEN AS SELECT * FROM read_csv_auto('/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/pfam_entries_full.dat')\")\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe the table\n",
    "con = duckdb.connect(database=ProteinDB.db_string)           \n",
    "\n",
    "res = con.execute(\"DESCRIBE PFAM_TOKEN\").fetchall()\n",
    "\n",
    "print(res)\n",
    "\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run a query\n",
    "con = duckdb.connect(database=ProteinDB.db_string)           \n",
    "count = con.execute(\"SELECT COUNT(*) FROM PFAM_TOKEN\").fetchall()\n",
    "print(count)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create index\n",
    "con = duckdb.connect(database=ProteinDB.db_string)      \n",
    "ind = con.execute(\"create index pfam_idx on PFAM_TOKEN (column0)\").fetchall()\n",
    "print(ind)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=ProteinDB.db_string)      \n",
    "res1 = con.execute(\"select column0, column1, column2, column3 from PFAM_TOKEN where column0='A0A000'\").fetchall()\n",
    "res2 = con.execute(\"select column0, column1, column2, column3 from PFAM_TOKEN where column0='Z9JZ56'\").fetchall()\n",
    "print(res1)\n",
    "print(res2)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Try a dictionary - also seemed slow\n",
    "#\n",
    "MAX_COUNT   = -1\n",
    "OUTPUT_LIMIT = 100000\n",
    "\n",
    "input = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/pfam_entries_full.dat\"\n",
    "\n",
    "def load_pfam_db():\n",
    "    count  = 0\n",
    "    con = duckdb.connect(database=ProteinDB.db_string) \n",
    "    \n",
    "    with open(input) as csvfile:\n",
    "        iprreader = csv.reader(csvfile, delimiter='\\t', quotechar='|')\n",
    "        for row in iprreader:\n",
    "            \n",
    "            uniprot_id  = row[0]\n",
    "            pfam_code   = row[1]\n",
    "            start       = row[2]\n",
    "            end         = row[3]\n",
    "            \n",
    "            print(uniprot_id, pfam_code, start, end)\n",
    "            \n",
    "            #con.execute(\"INSERT INTO PFAM_TOKEN (UNIPROT_ID, TOKEN, START_POS, END_POS) VALUES(?,?,?,?)\", (uniprot_id, pfam_code, start, end))\n",
    "            count += 1\n",
    "            \n",
    "            if (count % OUTPUT_LIMIT == 0):\n",
    "                print(count, 'lines processed.....')\n",
    "                \n",
    "             # -------- check for termination ------------\n",
    "            if(MAX_COUNT != -1):\n",
    "                if count >= MAX_COUNT:\n",
    "                    print('Processing limit reached %s stopping.' % (MAX_COUNT))\n",
    "                    return\n",
    "            # --------------------------------------------\n",
    "    con.close()\n",
    "    \n",
    "load_pfam_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COUNT   = 1000000\n",
    "OUTPUT_LIMIT = 1000\n",
    "\n",
    "input = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/pfam_entries_full.dat\"\n",
    "\n",
    "def load_pfam_dict():\n",
    "    count  = 0\n",
    "    proteins={}\n",
    "    \n",
    "    with open(input) as csvfile:\n",
    "        iprreader = csv.reader(csvfile, delimiter='\\t', quotechar='|')\n",
    "        for row in iprreader:\n",
    "            uniprot_id  = row[0]\n",
    "            pfam_code   = row[1]\n",
    "            start       = row[2]\n",
    "            end         = row[3]\n",
    "            \n",
    "            print('processing', uniprot_id, pfam_code, start, end)\n",
    "            if(uniprot_id in proteins.keys()):\n",
    "                #print(uniprot_id, 'already found')\n",
    "                #print(proteins[uniprot_id])\n",
    "                proteins[uniprot_id].append({pfam_code, start, end})\n",
    "            else:\n",
    "                #print('New entry:', uniprot_id)\n",
    "                proteins[uniprot_id] = [{pfam_code, start, end}]\n",
    "            #print(uniprot_id, pfam_code, start, end)\n",
    "            count +=1\n",
    "            \n",
    "            if (count % OUTPUT_LIMIT == 0):\n",
    "                print(count, 'lines processed.....')\n",
    "                \n",
    "             # -------- check for termination ------------\n",
    "            if(MAX_COUNT != -1):\n",
    "                if count >= MAX_COUNT:\n",
    "                    print('Processing limit reached %s stopping.' % (MAX_COUNT))\n",
    "                    #print(proteins) \n",
    "                    return\n",
    "            # --------------------------------------------\n",
    "    print('keys:', proteins)    \n",
    "load_pfam_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ucl_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
