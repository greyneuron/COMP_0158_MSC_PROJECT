{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "\n",
    "This notebook contains various scripts to assit with preparing distaance matrices for comparision with the evolutionary distances <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import time\n",
    "import re\n",
    "#\n",
    "# TODO - SET THIS STRING TO WHERE YOU WANT THE DB TO STORE ITS DATA\n",
    "#\n",
    "db_string = \"/Users/patrick/dev/ucl/comp0158_mscproject/database/w2v_20240731_test.db\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FIND UNIQUE EUKARYOTIC PFAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 - GET A LIST OF PFAM TOKENS THAT ARE ONLY RELEVANT TO EUKARYOTIC PROTEINS BY JOINING ACROSS TABLES\n",
    "#\n",
    "# W2V_TOKEN was created from protein2ipr.dat and thus has loads of non-eukaryiotic entries that are not relevant. \n",
    "# This script creates a list of pfam entries for eukaryotic proteins only by joining across tables:\n",
    "#\n",
    "# - W2V_PROTEIN_UREF100_E (has eukaryotic proteins in it and that it what was used to create the corpus)\n",
    "# - W2V_TOKEN   (has come from protein2ipr.dat and has many more pfam entries)\n",
    "#\n",
    "# W2V_PROTEIN_UREF100_E only has eukaryotic proteins in it and that it what was used to create the corpus\n",
    "#\n",
    "# For performance reasons, this script outputs to a number of separate files in 'chunks' - I used 500k on a Mac\n",
    "\n",
    "\n",
    "# output directory for each 'chunk of pfam ids'\n",
    "output_file_root = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/tmp/eukaryotic_pfam_smart_not_unique_\"\n",
    "\n",
    "def get_eukaryotic_pfams(start_pos, end_pos, iteration):\n",
    "    #print(f\"iteration {iteration} from {start_pos} to {end_pos}.\")\n",
    "    s = time.time()\n",
    "    \n",
    "    output_file = output_file_root+ str(iteration) + \".txt\"\n",
    "    # create long life/expensive objects\n",
    "    of  = open(output_file, \"w\")\n",
    "    con = duckdb.connect(database=db_string)\n",
    "    \n",
    "    try:\n",
    "        results = con.execute(f\"SELECT W2V_PROTEIN_UREF100_E.UNIPROT_ID, W2V_TOKEN.TOKEN FROM ( SELECT UNIPROT_ID FROM W2V_PROTEIN_UREF100_E WHERE COUNTER >= {start_pos} and COUNTER < {end_pos}) AS W2V_PROTEIN_UREF100_E INNER JOIN W2V_TOKEN AS W2V_TOKEN ON W2V_PROTEIN_UREF100_E.UNIPROT_ID = W2V_TOKEN.UNIPROT_ID WHERE W2V_TOKEN.TYPE = 'PFAM' \").fetchall()\n",
    "    except Exception as e:\n",
    "        print(f\"Error on iteration {iteration}, {e}, closing finr {output_file}\")\n",
    "        of.close()\n",
    "        con.close()\n",
    "        return\n",
    "    e1 = time.time()\n",
    "\n",
    "    for res in results:\n",
    "        #print(res[1])\n",
    "        of.write(res[1] +'\\n')        \n",
    "    e2 = time.time()\n",
    "\n",
    "    print(f\"iteration {iteration} from {start_pos} to {end_pos}. query took {e1-s}s, overall took {e2-s}s\")\n",
    "\n",
    "    of.close()\n",
    "    con.close()\n",
    "\n",
    "num_eukaryotic = 95272305\n",
    "start_pos       = 0    # start point\n",
    "chunk_size      = 500000    # how many rows to return\n",
    "end_pos         = chunk_size\n",
    "iterations      = (num_eukaryotic // chunk_size) + 1\n",
    "\n",
    "\n",
    "print(iterations, 'required.')\n",
    "\n",
    "for i in range(iterations):\n",
    "    get_eukaryotic_pfams(start_pos, end_pos, i)\n",
    "    start_pos += chunk_size\n",
    "    end_pos += chunk_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2 - COMBINE OUTPUTS FROM STEP 1\n",
    "\n",
    "# Use the shell script : 'combine_pfam_list.sh' to combine the output from step 1 into a single list\n",
    "#\n",
    "# INPUT: Individual chunked files from step 1\n",
    "# OUTPUT : A single file with only eukaryotic pfam entries \n",
    "#\n",
    "# chunked files : /Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/tmp\n",
    "# unique eukaryotic pfams: /Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/unique_eukaryotic_pfam.txt\n",
    "#\n",
    "# there is an interim file created by this script before the unique list is extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Creating a list of pfam ids without the 'PF' - this will alow me to store them in a \n",
    "# numpy array. Also going to save to a database\n",
    "#\n",
    "def create_pfam_analysis_list():\n",
    "    \n",
    "    pfam_file   = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/unique_eukaryotic_pfam.txt\"\n",
    "    output_file = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/unique_eukaryotic_pfam_ids.txt\"\n",
    "    \n",
    "    output = open(output_file, \"w\")\n",
    "    with open(pfam_file, \"r\") as pfam_data:\n",
    "        for line_number, line in enumerate(pfam_data):\n",
    "            \n",
    "            line = line.rstrip()\n",
    "            line = line.lstrip()\n",
    "            \n",
    "            my_search  = re.search(\"PF([0-9]*)\", line)\n",
    "            pf_root      = my_search.group(1)\n",
    "            \n",
    "            buffer = \"|\".join([str(line_number + 1), pf_root, line])\n",
    "            print(buffer)\n",
    "            output.write(buffer +'\\n')\n",
    "    output.close()        \n",
    "\n",
    "create_pfam_analysis_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Create ouptut file with ids\n",
    "#\n",
    "# Creating a list of pfam ids without the 'PF' - this will alow me to store them in a \n",
    "# numpy array. Also going to save to a database\n",
    "#\n",
    "def create_pfam_analysis_list():\n",
    "    \n",
    "    pfam_file   = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/unique_eukaryotic_pfam.txt\"\n",
    "    output_file = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/unique_eukaryotic_pfam_ids.txt\"\n",
    "    \n",
    "    output = open(output_file, \"w\")\n",
    "    with open(pfam_file, \"r\") as pfam_data:\n",
    "        for line_number, line in enumerate(pfam_data):\n",
    "            \n",
    "            line = line.rstrip()\n",
    "            line = line.lstrip()\n",
    "            \n",
    "            my_search  = re.search(\"PF([0-9]*)\", line)\n",
    "            pf_root      = my_search.group(1)\n",
    "            \n",
    "            buffer = \"|\".join([str(line_number + 1), pf_root, line])\n",
    "            print(buffer)\n",
    "            output.write(buffer +'\\n')\n",
    "    output.close()        \n",
    "\n",
    "create_pfam_analysis_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Creates a new table with only eukaryotic PFAM entries - these will be encoded for ever model\n",
    "#\n",
    "con = duckdb.connect(database=db_string)\n",
    "\n",
    "output_file = \"/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/unique_eukaryotic_pfam_ids.txt\"          \n",
    "con.execute(\"CREATE TABLE W2V_PFAM_E AS SELECT * FROM read_csv_auto('/Users/patrick/dev/ucl/comp0158_mscproject/data/pfam/unique_eukaryotic_pfam_ids.txt', columns={'COUNTER' :'USMALLINT', 'STRIPPED_PFAM_ID': 'USMALLINT', 'PFAM_ID': 'VARCHAR'})\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15577,)\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(database=db_string)           \n",
    "count = con.execute(\"SELECT COUNT(*) FROM W2V_PFAM_E\").fetchall()\n",
    "print(count[0])\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'PF00002')\n",
      "(2, 'PF00003')\n",
      "(3, 'PF00004')\n",
      "(4, 'PF00005')\n",
      "(5, 'PF00006')\n",
      "(6, 'PF00007')\n",
      "(7, 'PF00008')\n",
      "(8, 'PF00009')\n",
      "(9, 'PF00010')\n",
      "(10, 'PF00011')\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(database=db_string)           \n",
    "results = con.execute(\"SELECT COUNTER, PFAM_ID FROM W2V_PFAM_E WHERE COUNTER >0 AND COUNTER <= 10\").fetchall()\n",
    "for res in results:\n",
    "    print(res)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create table for list of EVO PFAM IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=db_string)\n",
    "         \n",
    "con.execute(\"CREATE TABLE W2V_EVO_PFAM AS SELECT * FROM read_csv_auto('/Users/patrick/dev/ucl/comp0158_mscproject/code/evolutionary/evo_pfam_ids.dat', columns={'COUNTER' :'USMALLINT', 'PFAM_ID': 'VARCHAR'})\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(20651,)]\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(database=db_string)  \n",
    "count = con.execute(\"SELECT COUNT(*) FROM W2V_EVO_PFAM\").fetchall()\n",
    "print(count)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UTILITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for PFAM and PROTEIN ENTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W2V_PROTEIN [('A0A010PZJ8', 1, 494)]\n",
      "W2V_PROTEIN_UREF100_E [('UniRef100', 'A0A010PZJ8', 493, 1, 494, 1, 1445577, 'Colletotrichum fioriniae PJ7')]\n"
     ]
    }
   ],
   "source": [
    "# test that W2V_TOKEN has all pfam and disorder entries\n",
    "# 1445577   : Colletotrichum fioriniae PJ7\n",
    "# 10116     : Rattus norvegicus\n",
    "con = duckdb.connect(database=db_string)\n",
    "\n",
    "# 1. Test - find a protein with pfam entries\n",
    "#    - Both of these work\n",
    "#protein_id = \"A0A009GYB3\" # this is prob not eukaryotic\n",
    "protein_id = \"A0A010PZJ8\"\n",
    "\n",
    "#tokens = con.execute(\"SELECT * FROM W2V_TOKEN WHERE UNIPROT_ID = 'A0A009GYB3'\").fetchall()\n",
    "#tokens = con.execute(\"SELECT * FROM W2V_TOKEN WHERE UNIPROT_ID = (?)\", [protein_id] ).fetchall()\n",
    "\n",
    "# 2. Find that same protein in W2V_PROTEIN\n",
    "# doesn't work - possibly because the pfam entries are from all proteins whereas W2V_PROTEIN only\n",
    "# has TrEMBL Eukaryotic proteins\n",
    "#tokens = con.execute(\"SELECT * FROM W2V_PROTEIN WHERE UNIPROT_ID = 'A0A009GYB3'\").fetchall()\n",
    "tokens = con.execute(\"SELECT * FROM W2V_PROTEIN WHERE UNIPROT_ID = (?)\", [protein_id]).fetchall()\n",
    "print('W2V_PROTEIN', tokens)\n",
    "\n",
    "# doesn't work\n",
    "#tokens = con.execute(\"SELECT * FROM W2V_TOKEN WHERE UNIPROT_ID = (?)\", ['protein_id']).fetchall()\n",
    "\n",
    "# none of these work - is the protein A0A009GYB3 in UniRef??\n",
    "# tokens = con.execute(\"SELECT * FROM W2V_PROTEIN_UNIREF_100_ALL_TAX WHERE UNIPROT_ID = 'A0A009GYB3'\").fetchall()\n",
    "tokens = con.execute(\"SELECT * FROM W2V_PROTEIN_UREF100_E WHERE UNIPROT_ID = (?)\", [protein_id]).fetchall()\n",
    "# tokens = con.execute(\"SELECT * FROM W2V_PROTEIN_UNIREF_100_ALL_TAX WHERE UNIPROT_ID = (?)\", [protein_id]).fetchall()\n",
    "# grep \"A0A009GYB3\" uniref100_tax_20240801.dat > returns nothing\n",
    "\n",
    "print('W2V_PROTEIN_UREF100_E', tokens)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('E', '710243', '1445577')]\n",
      "[('1445577', 'Colletotrichum fioriniae PJ7')]\n"
     ]
    }
   ],
   "source": [
    "# test that W2V_TOKEN has all pfam and disorder entries\n",
    "# 1445577   : Colletotrichum fioriniae PJ7\n",
    "# 10116     : Rattus norvegicus\n",
    "con = duckdb.connect(database=db_string)           \n",
    "tokens = con.execute(\"SELECT * FROM W2V_TAX_CAT WHERE ID=(?)\", ['1445577']).fetchall()\n",
    "print(tokens)\n",
    "tokens = con.execute(\"SELECT * FROM W2V_TAX_NAME WHERE TAX_ID=(?)\", ['1445577']).fetchall()\n",
    "print(tokens)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect(database=db_string)           \n",
    "con.execute(\"DROP TABLE X\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('W2V_PFAM_E',), ('W2V_PROTEIN',), ('W2V_PROTEIN_UNIREF_100_ALL_TAX',), ('W2V_PROTEIN_UREF100_E',), ('W2V_TAX_CAT',), ('W2V_TAX_NAME',), ('W2V_TOKEN',)]\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(database=db_string)           \n",
    "tables = con.execute(\"SHOW TABLES\").fetchall()\n",
    "print(tables)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('COUNTER', 'USMALLINT', 'YES', None, None, None), ('STRIPPED_PFAM_ID', 'USMALLINT', 'YES', None, None, None), ('PFAM_ID', 'VARCHAR', 'YES', None, None, None)]\n"
     ]
    }
   ],
   "source": [
    "con = duckdb.connect(database=db_string)           \n",
    "tables = con.execute(\"DESCRIBE W2V_PFAM_E\").fetchall()\n",
    "print(tables)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlock database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import duckdb\n",
    "import os\n",
    "\n",
    "# this doesn;t seem to work....\n",
    "def is_locked():\n",
    "    lock_file = f'{db_string}.lock'\n",
    "    return os.path.exists(lock_file)\n",
    "\n",
    "is_locked()\n",
    "\n",
    "# ... but this does from a command prompt\n",
    "#fuser database/proteins.db\n",
    "\n",
    "fuser /Users/patrick/dev/ucl/comp0158_mscproject/database/w2v_20240731_test.db\n",
    "\n",
    "# then kill -9 <id if there is one list>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_ucl_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
